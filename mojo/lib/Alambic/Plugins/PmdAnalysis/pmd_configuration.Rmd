---
#########################################################
#
# Copyright (c) 2015-2017 Castalia Solutions and others.
#
# All rights reserved. This program and the accompanying materials
# are made available under the terms of the Eclipse Public License v1.0
# which accompanies this distribution, and is available at
# http://www.eclipse.org/legal/epl-v10.html
#
# Contributors:
#   Boris Baldassari - Castalia Solutions
#
#########################################################

title: "PMD Configuration"
author:
- name: "Boris Baldassari"
  affiliation: Castalia Solutions
output:
  html_fragment:
    toc: false
    fig_caption: true
    fig.width: 800
    self_contained: false
    lib_dir: libs
    echo: false
    dev: svg
---

```{r init, echo=FALSE, message=FALSE}

library(knitr)
require(ggplot2)
require(xtable)

opts_chunk$set(echo=F, fig.path = 'figures/')

priority.colours <- c("#CC0000", "#DD5500", "#EEAA00", "#FFCC66")

#project.id <- 'modeling.sirius'
pmd.main <- read.csv(file=paste("../../../../projects/", project.id, "/output/", project.id, "_pmd_analysis_main.csv", sep=""), header=T)
pmd.rules <- read.csv(file=paste("../../../../projects/", project.id, "/output/", project.id, "_pmd_analysis_rules.csv", sep=""), header=T)
pmd.rulesets <- read.csv(file=paste("../../../../projects/", project.id, "/output/", project.id, "_pmd_analysis_rulesets2.csv", sep=""), header=T)
pmd.violations <- read.csv(file=paste("../../../../projects/", project.id, "/output/", project.id, "_pmd_analysis_violations.csv", sep=""), header=T)
pmd.files <- read.csv(file=paste("../../../../projects/", project.id, "/output/", project.id, "_pmd_analysis_files.csv", sep=""), header=T)
```

## PMD Configuration analysis for `r I(project.id)`

<br />

<div class="row"><div class="col-sm-7">

[PMD](http://pmd.sourceforge.net) is a great and widely-used source code analyzer which finds common programming flaws and bad coding practices in source code projects. This document intends to help users configure the tools and select the right rulesets for a more efficient use of the tool.

* The quick summary helps users <a href="#summary">understand the reports</a> generated by the tool
* The <a href="#improve-usage-rulesets">rulesets overview</a> provides basic information about the rulesets detected in the violations.
* The <a href="#improve-usage-rules">rules selection</a> section proposes to remove rules that produce too many violations to be actionable and have a low priority, to allow users to better focus on pragmatic actions.
* Finally, the <a href="#improve-usage-next">continuous improvement</a> section proposes steps to incrementally improve the quality of your project.

The version of PMD used is ``r pmd.main$PMD.version[1]`` and the PMD run was executed on the ``r as.POSIXct(pmd.main$Timestamp[1], format="%Y-%m-%dT%H:%M:%S")``.

You can learn more about this module on its [documentation page](http://alambic.io/Plugins/Prex/PmdAnalysis.html) on the [project web site](http://alambic.io/).

</div><div class="col-sm-4">

<div class="panel panel-default">
<div class="panel-heading"><h3 class="panel-title">Contents</h3></div>
<div class="list-group">
  <a href="#summary" class="list-group-item">Quick Summary</a>
  <a href="#improve-usage-rulesets" class="list-group-item">Rulesets overview</a>
  <a href="#improve-usage-rules" class="list-group-item">Rules selection</a>
  <a href="#improve-usage-next" class="list-group-item">Continuous improvement</a>
  <a href="#downloads" class="list-group-item">Downloads</a>
</div></div>

</div></div>

-----

### <a name="summary"></a>Quick Summary

<div class="row"><div class="col-sm-6">

PMD raised a total of ``r sum(pmd.main$NCC)`` violations to checked rules, including:

* ``r sum(pmd.files$NCC_1)`` with <span style="color: #CC0000">priority 1</span>,
* ``r sum(pmd.files$NCC_2)`` with <span style="color: #DD5500">priority 2</span>,
* ``r sum(pmd.files$NCC_3)`` with <span style="color: #EEAA00">priority 3</span>,
* ``r sum(pmd.files$NCC_4)`` with <span style="color: #FFCC66">priority 4</span>.

**Rules** can be considered as **coding practices**. They represent what the community believes to be right or wrong, althougth it heavily depends on your own context. In this very case:

* A total of ``r sum(pmd.main$RULES)`` rules have been checked.
* The analysis found ``r sum(pmd.main$RKO)`` broken rules, and ``r sum(pmd.main$ROK)`` respected rules.
* So the rate of <strong>acquired practices</strong> is ``r round(sum(pmd.main$ROKR), digits=1)`` %.

</div><div class="col-sm-6">

This plot shows the proportion of rules violated (<span class="label" style="background-color: #CC0000">NOK: red</span>) and clean (<span class="label" style="background-color: #325d88">OK: blue</span>). The lightness decreases with the priority (P1 -> p4).

<iframe src="/projects/`r project.id`/PmdAnalysis/pmd_configuration_summary_pie.html" frameborder="0" style="width: 100%; height: 320px"></iframe>

</div></div>

-----

### <a name="improve-usage"></a>Improving PMD usage

Having too many violations just does not help. Most developers will feel overwhelmed by thousands of violations, and from a practical point of view they just wont spend days or weeks fixing violations on a product that works - would you yourself?

That is why it is important to [customise PMD to fit your needs](http://pmd.sourceforge.net/bestpractices.html). It usually boils down to the following steps.

-----

### <a name="improve-usage-rulesets"></a>Investigate rulesets

If you are quite new to PMD, the first thing to do is to *investigate and try the rulesets*. Start with some of the obvious rulesets - just run [unusedcode](http://pmd.sourceforge.net/rules/unusedcode.html) and fix any unused locals and fields. Then, run [basic](http://pmd.sourceforge.net/rules/basic.html) and fix all the empty <code>if</code> statements and such-like. Then peruse the [design](http://pmd.sourceforge.net/rules/design.html), [coupling](http://pmd.sourceforge.net/rules/coupling.html) and [controversial](http://pmd.sourceforge.net/rules/controversial.html) rulesets.

The bottom line is to find rules that are both **important** - you can rely on the *priority* of the rule for that - and *actionable*, that is they do not show thousands of violations. The latter is because beside the fact it is discouraging for developers, it means that your project is probably not mature enough regarding this practice. **Start small, secure practices, and expand the scope**.

The rulesets detected in the current PMD log are ``r paste(unique(pmd.rulesets$ruleset), sep=", ")``, which represent a total of ``r sum(pmd.main$RULES)`` practices checked. The following graphic shows *the number of violations classified by ruleset*. Violations are sorted according to their priority, from 1 (high impact) to 4 (information). The table on the right provides the data for this graph, with the overall number of violations for each ruleset, and for each priority.


<div class="row"><div class="col-lg-6">

<img src="/projects/`r project.id`/PmdAnalysis/pmd_configuration_rulesets_repartition.svg" frameborder="0" style="width: 100%; height: 400px" />

</div><div class="col-sm-6">
<br />
```{r rulesets-repartition-table, results='asis', warning=F}
# Create data.frame
tmp.rulesets <- data.frame(unique(pmd.rulesets$ruleset))
names(tmp.rulesets) <- c('ruleset')

# Add NCC_1, NCC_2, NCC_3, NCC_4 vol from columns with priority
tmp.rulesets <- merge(x=tmp.rulesets,
                     y=subset(pmd.rulesets, priority == 1)[-2],
                     by="ruleset", all=TRUE)
tmp.rulesets <- merge(x=tmp.rulesets,
                     y=subset(pmd.rulesets, priority == 2)[-2],
                     by="ruleset", all=TRUE)
tmp.rulesets <- merge(x=tmp.rulesets,
                     y=subset(pmd.rulesets, priority == 3)[-2],
                     by="ruleset", all=TRUE)
tmp.rulesets <- merge(x=tmp.rulesets,
                     y=subset(pmd.rulesets, priority == 4)[-2],
                     by="ruleset", all=TRUE)

# Replace NAs with zeros
tmp.rulesets[is.na(tmp.rulesets)] <- 0

# Add sum in NCC column
tmp.rulesets$NCC <- rowSums(tmp.rulesets[,2:4])

# Rename columns
names(tmp.rulesets) <- c('Ruleset', 'NCC_1', 'NCC_2', 'NCC_3', 'NCC_4', 'NCC')

# Rebuild final data frame
tmp.rulesets.final <- tmp.rulesets[,c('Ruleset', 'NCC', 'NCC_1', 'NCC_2', 'NCC_3', 'NCC_4')]

print(
    xtable(tmp.rulesets.final, digits=0,
        caption = 'Rulesets detected in this PMD analysis.'),
    type="html",
    html.table.attributes='class="table table-striped"',
    include.rownames=FALSE
)
```

</div></div>

-----

### <a name="improve-usage-rules"></a>Select and customise rules

Once you get to know what rules are available, and started identify some of them as really smart and relevant for you, you should then [create your own ruleset](http://pmd.sourceforge.net/howtomakearuleset.html). Creating your own ruleset makes it easier to run PMD by selecting entire rulesets, excluding or specifically adding specific rules. It also gives you more control over the analysis&apos; execution by excluding some files or directories.

The following graphic shows all rules violated in this project&apos;s code, sorted according to the number of violations. The colour of the bars varies from <span style="color: #CC0000">red</span> (priority 1) to <span style="color: #FFCC66">yellow</span> (priority 4). Please note that the y axis is logarithmic, so small numbers can still be identified despite the high-volume rules.

<img src="/projects/`r project.id`/PmdAnalysis/pmd_configuration_violations_rules.svg" frameborder="0" style="width: 100%; height: 600px" />

```{r violations-rules}

pmd.violations.sorted <- pmd.violations[order(pmd.violations$vol),]
pmd.violations.sorted$csum <- cumsum(pmd.violations.sorted$vol)

# Get the threshold for rules that have priority > 2 and many violations.
pmd.violations.threshold <- head(pmd.violations.sorted[pmd.violations.sorted$priority >= 3 & pmd.violations.sorted$vol > 500,c(5)], n=1)

exclude.rules <- pmd.violations.sorted[pmd.violations.sorted$csum >= pmd.violations.threshold,c(1,2,4)]
pmd.violations.removed <- sum(exclude.rules$vol)
exclude.rules <- exclude.rules[with(exclude.rules, order(-vol)),]

write.csv(exclude.rules, file=paste(project.id, "_pmd_analysis_exclude_rules.csv", sep=""), row.names=F)

```

<div class="row"><div class="col-lg-6">

At least during the early steps, rules with a high number of violations (e.g. > 500) and a low priority (like P3 and P4) can simply be discarded. On the above plot, they correspond to all yellow bars to the right of the last right red or orange bar. In the current case there are ``r length(exclude.rules$Mnemo)`` rules that can be excluded, which represent together ``r pmd.violations.removed`` violations. They are listed in the table on the right. By removing these rules, the number of violations should fall down from ``r sum(pmd.main$NCC)`` to ``r pmd.violations.threshold``.

If some rules seem to be relevant but give unexpected results, try to tune them. Many rules can be given properties to alter their behaviour. As an example, the [EmptyCatchBlock](http://pmd.sourceforge.net/rules/basic.html#EmptyCatchBlock) rule from the [basic ruleset](http://pmd.sourceforge.net/rules/basic.html) has a Java property `allowCommentedBlocks` to skip empty blocks  comments for this rule.

</div><div class="col-lg-6">

```{r violations-rules-table, results='asis', warning=F}
print(
  xtable(
    exclude.rules,
    caption = 'Rules that can be removed to lower the number of violations.',
    digits=0),
  type="html",
  html.table.attributes='class="table table-striped"',
  caption.placement='bottom',
  include.rownames=FALSE
)
```

</div></div>

-----

### <a name="improve-usage-next"></a>Continuous improvement

Well, if you did that already you should have a much more concise and clean perspective on PMD results. Improving the project quality is probably the best thing to do now, at least to catch the most important bugs (with the highest priority). Once you are done, come back to this section and try to add some more meaningful rules to continuously improve your code.

-----

### <a name="downloads"></a>Downloads

The visualisations on this page can be exported and easily reused on an external web site. You can find more information on iframes and pictures reuse in [the project&apos;s web site](http://alambic.io/Documentation/Basic/Export.html). Remember to change the server name in the code samples provided.

Pie chart of checked and broken rules

    <iframe src="http://server/projects/`r project.id`/PmdAnalysis/pmd_configuration_summary_pie.html" frameborder="0" style="width: 100%; height: 320px"></iframe>

Files with high priority violations

    <img src="http://server/projects/`r project.id`/PmdAnalysis/pmd_configuration_rulesets_repartition.svg" frameborder="0" style="width: 100%; height: 600px" />

Top 5 high-priority rules

    <img src="http://server/projects/`r project.id`/PmdAnalysis/pmd_configuration_violations_rules.svg" frameborder="0" style="width: 100%; height: 600px" />

The visualisations used in this document rely on a number of flat CSV and JSON data files, that were extracted from the PMD XML results file. You can download and play with them if you want to thereafter:

* Generic information about the project : PMD version, timestamp of analysis, number of non-conformities, number of rules checked, number of rules violated, number of clean rules, rate of acquired practices [ <a href="pmd_analysis_main.csv">Download CSV</a> ]
* Rules: number of non-conformities for each category of rules and priority [ <a href="pmd_analysis_rules.csv">Download CSV</a> ].
* Violations: foreach violated rule, its priority, the ruleset it belongs to, and the volume of violations [ <a href="pmd_analysis_violations.csv">Download CSV</a> ]
* Files: for each non-conform file, its name, total number of non-conformities, number of non-conformities for each priority, number of broken and clean rules, and the rate of acquired practices [ <a href="pmd_analysis_files.csv">Download CSV</a> ]
* Rulesets detected in the analysis output, with number of violations for each priority [ <a href="pmd_analysis_rulesets.csv">Download CSV (wide format)</a> | <a href="pmd_analysis_rulesets2.csv">Download CSV (long format)</a> ]
* List of violated rules, with priority, ruleset and number of non-conformities [ <a href="pmd_analysis_violations.csv">Download CSV</a> | <a href="pmd_analysis_violations.json">Download JSON</a> ]
